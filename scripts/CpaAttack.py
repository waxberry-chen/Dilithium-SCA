import os
from typing import Tuple
import numpy as np
from multiprocessing import Pool,shared_memory
from numpy.core.multiarray import ravel_multi_index
from tqdm import tqdm as tq
import multiprocessing as mp
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
import json
import linecache

matplotlib.use('Agg')

high_contrast_colors = [   
            '#FFD700',  # é‡‘é»„è‰²
            '#FF6347',  # ç•ªèŒ„çº¢
            '#FF8C00',  # æ·±æ©™è‰²
            '#FF4500',  # æ©™çº¢è‰²
            '#FF1493',  # æ·±ç²‰è‰²
            '#8B0000',  # æ·±çº¢è‰²
            '#FFA500',  # æ©™è‰²
            '#B22222',  # ç –çº¢è‰²
            '#800000',  # æ —è‰²
            '#FF4500',  # æ©™çº¢è‰²
        ]

#### get the pearson coorelation between two matrix

def column_pearson_corr(matrix1, matrix2):
    """
    è®¡ç®—ä¸¤ä¸ªçŸ©é˜µçš„åˆ—é—´ Pearson ç›¸å…³ç³»æ•°
    å‚æ•°:
    matrix1, matrix2 -- ç›¸åŒå½¢çŠ¶çš„äºŒç»´ numpy æ•°ç»„ (mxn)
    è¿”å›:
    ç›¸å…³ç³»æ•°çŸ©é˜µ -- å½¢çŠ¶ä¸º (1, n) çš„ numpy æ•°ç»„
    """

    # ç¡®ä¿çŸ©é˜µå½¢çŠ¶ç›¸åŒ
    assert matrix1.shape == matrix2.shape, "çŸ©é˜µå½¢çŠ¶å¿…é¡»ç›¸åŒ"

    # ä¸­å¿ƒåŒ–çŸ©é˜µ
    center1 = matrix1 - np.mean(matrix1, axis=0, keepdims=True)
    center2 = matrix2 - np.mean(matrix2, axis=0, keepdims=True)

    # è®¡ç®—åˆ†å­ (åæ–¹å·®æ±‚å’Œ)
    numerator = np.sum(center1 * center2, axis=0)

    # è®¡ç®—åˆ†æ¯ (æ ‡å‡†å·®ä¹˜ç§¯)
    denominator = np.sqrt(np.sum(center1 ** 2, axis=0)) * np.sqrt(np.sum(center2 ** 2, axis=0))

    # å¤„ç†åˆ†æ¯ä¸ºé›¶çš„æƒ…å†µ (è®¾ä¸º0é¿å…NaN)
    denominator[denominator == 0] = np.inf

    # è®¡ç®—ç›¸å…³ç³»æ•°
    corr = numerator / denominator

    # è¿”å›è¡Œå‘é‡ (1Ã—n)
    return corr.reshape(1, -1)

### get distance in cycle 7

a_last = 0
qNUM = 3329

########################################
#     Get Prediction Vector Method     #
########################################
def distance(plaintexts,key):
    global a_last
    p0 = 0
    for i in range(3):
        p0 += HD((plaintexts[2-i]*key),(plaintexts[3-i]*key))

    input_7 = HD(plaintexts[5], 0)
    input_6 = HD(plaintexts[4], plaintexts[5])
    input_5 = HD(plaintexts[3], plaintexts[4])
    input_4 = HD(plaintexts[2], plaintexts[3])
    input_3 = HD(plaintexts[1], plaintexts[2])
    input_2 = HD(plaintexts[0], plaintexts[1])
    input_1 = HD(a_last, plaintexts[0])

    mm_result = HD(plaintexts[0]*key%qNUM, plaintexts[1]*key%qNUM)
    output = HD((a_last*key)%qNUM, (plaintexts[0]*key)%qNUM)

    a_last = plaintexts[4]
    # return output + mm_result
    return output + mm_result

    # ##### Verify #####
    # wn = 1729
    # N = 3329
    # a_val = plaintexts[0]
    # product_guess = (key * wn) % N
    # c_sum = a_val + product_guess
    # c_val = c_sum - N if c_sum >= N else c_sum
    # return HD(c_val, 0)


def HD(num1,num2):
    return bin(num2^num1).count('1')


#### get the correlation by multiprocesses

def process_key_wrapper(args):
    """åŒ…è£…å‡½æ•°ï¼Œç”¨äºå¤„ç†å•ä¸ªå¯†é’¥"""
    key, power_trace_mat, plaintext_list = args
    return process_key(key, power_trace_mat, plaintext_list)


def process_key(key, power_trace_mat, plaintext_list):
    """å¤„ç†å•ä¸ªå¯†é’¥çš„å‡½æ•°ï¼ˆç‹¬ç«‹äºç±»ï¼‰"""
    sample_number = power_trace_mat.shape[1]
    H_distance_mat = np.zeros((len(plaintext_list), sample_number))

    for index, plaintexts in enumerate(plaintext_list):
        
        h = distance(plaintexts, key)
        # if (key == 2773) & ((index % 500 == 0) | (index % 500 == 1)):
        #     print(f"--- [DEBUG] h = {h}; plaintext = {plaintexts}; key = {key}\n\t\toutput = {(plaintexts[0]*key)%qNUM}, {(plaintexts[1]*key)%qNUM}, {(plaintexts[2]*key)%qNUM}, {(plaintexts[3]*key)%qNUM}, {(plaintexts[4]*key)%qNUM}, {(plaintexts[5]*key)%qNUM}")
        H_distance_mat[index, :] = h

    return key, column_pearson_corr(power_trace_mat, H_distance_mat)


def get_plaintexts(file_path,trace_number,plaintext_num=6):
    plaintexts = []
    for i in range(plaintext_num):
        line = linecache.getline(file_path, trace_number+i+1).rstrip('\n') #ä»1å¼€å§‹(HERE)
        if not line or line.isspace():
            raise ValueError(f"Plaintexts file line num not enough or cant find file {file_path}")
        plaintexts.append(int(line)) 
    return plaintexts  

     # é™é‡‡æ ·å‚æ•°
class CPA:
    def __init__(self, power_trace_file, random_plaintext_file,
                 sample_number=5000, traces_number=3329, 
                 guess_key_start = 0, guess_key_end = 3328,
                 process_number=None,
                 low_sample = None,
                 high_sample = None,
                 ):

        self.power_trace_file = power_trace_file
        self.random_plaintext_file = random_plaintext_file
        self.sample_number = sample_number
        #self.key_number = key_number
        self.guess_keys = [key for key in range(guess_key_start,guess_key_end+1)]
        self.key_number = len(self.guess_keys)
        self.traces_number = traces_number
        self.process_number = process_number or max(1, mp.cpu_count() - 1)

        if low_sample is not None:
            self.low_sample = low_sample
        else:
            self.low_sample = 0
        
        if high_sample is not None:
            self.high_sample = high_sample
        else :
            self.high_sample = sample_number
        
        self.sample_number = self.high_sample - self.low_sample

        self.plaintext_list = []
        self.power_trace_mat = None
        
    def read_power(self,down_sample_factor=1):
        """è¯»å–åŠŸè€—è½¨è¿¹æ•°æ®"""
        self.power_trace_mat = np.zeros((self.traces_number, self.sample_number))
        # è¿›åº¦æ¡
        with tq(total=self.traces_number, desc=">>>>> 01 Reading Power traces") as read_bar:
            with open(self.power_trace_file, 'r') as pf:
                number = 0
                # Read traces into matrix
                for line in pf:
                    if number >= self.traces_number or not line.strip():
                        break
                    else:
                        plaintext_str, power_trace_str = line.split(':', 1)
                        plaintext_number = int(plaintext_str)
                        power_trace = np.array(power_trace_str.strip().split()).astype(np.float64)
                        # >>> Slice >>>
                        power_trace = power_trace[self.low_sample:self.high_sample]
                        # >>> Save to matrix >>>
                        self.power_trace_mat[plaintext_number, :] = power_trace
                        ## changed
                        # if plaintext_number:
                        #     current_plaintexts = get_plaintexts(self.random_plaintext_file,plaintext_number-1)
                        # else :
                        #     current_plaintexts = get_plaintexts(self.random_plaintext_file,plaintext_number)
                        current_plaintexts = get_plaintexts(self.random_plaintext_file,plaintext_number)
                        ## change end
                        self.plaintext_list.append(current_plaintexts)
                        # if number % 500 == 0:
                        #     print(f"\n--- [DEBUG] è½¨è¿¹è®¡æ•°: {number} (æ–‡ä»¶ä¸­çš„ plaintext_number: {plaintext_number}) ---")
                        #     print(f"--- [DEBUG] Plaintexts: {current_plaintexts}\n")
                        number += 1
                        read_bar.update(1)
                    
                
        # ç¡®ä¿æ•°ç»„å¤§å°æ­£ç¡®
        if number < self.traces_number:
            self.power_trace_mat = self.power_trace_mat[:number, :]
            self.traces_number = number
        print(f"INFO: 1. Successfully read {len(self.plaintext_list)} power traces")
        print(f"INFO: 2. Power traces matrix size: ({self.power_trace_mat.shape[0]} x {self.power_trace_mat.shape[1]})")
        ##### DownSample #####
        if down_sample_factor > 1:
            print(f"\tINFO: Down Sampling activated, processing...")
            sample_downsize = self.power_trace_mat.shape[1] // down_sample_factor
            self.power_trace_mat = self.power_trace_mat[:, :sample_downsize * down_sample_factor].reshape(self.power_trace_mat.shape[0], sample_downsize, down_sample_factor).max(axis=2)
            self.sample_number = sample_downsize
            print(f"\tINFO: Resize into ({self.power_trace_mat.shape[0]} x {sample_downsize})")

    def analyze(self,output_file=None):
        """å¹¶è¡Œåˆ†ææ‰€æœ‰å¯†é’¥"""
        print(f">>>>> 02 Starting parallel CPA analysis with {self.process_number} processes...")
        # å‡†å¤‡ä»»åŠ¡å‚æ•°
        # tasks = [(key, self.power_trace_mat, self.plaintext_list)
        #          for key in range(self.key_number)]
        tasks = [(key, self.power_trace_mat, self.plaintext_list)
                 for key in self.guess_keys]
        self.result = {}
        # ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œå¤„ç†
        with Pool(processes=self.process_number) as pool:
            # ä½¿ç”¨imap_unorderedè·å–ç»“æœï¼ˆæ— åºä½†æ›´å¿«ï¼‰
            with tq(total=self.key_number, desc="    Analyzing keys") as pbar:
                for key, corr in pool.imap_unordered(process_key_wrapper, tasks, chunksize=10):
                    self.result[key] = corr
                    pbar.update(1)

                    # æ¯å¤„ç†100ä¸ªå¯†é’¥æ›´æ–°ä¸€æ¬¡è¿›åº¦
                    if pbar.n % 100 == 0:
                        pbar.set_postfix(processed=f"{pbar.n}/{self.key_number}")
        if output_file:
            with open(output_file,'w') as of:
                json.dump(self.result, of, ensure_ascii=False, indent=4,
                default=lambda x: x.tolist() if isinstance(x, np.ndarray) else x.item() if isinstance(x, np.generic) else TypeError) 
        print('\tINFO: CPA analysis completed successfully!')
        return self.result


class Draw:
    def __init__(self,picture_save_path,sample_number=5000,key_number=3329,
                guess_key_start = 0, guess_key_end = 3328,
                top_key_num = 5,
                compare_window:Tuple[int,int]=(None,None),
                ) -> None:
        self.save_path = picture_save_path
        self.sample_number = sample_number
        self.guess_keys = [key for key in range(guess_key_start,guess_key_end+1)]
        #self.key_number = key_number
        self.key_number = len(self.guess_keys)
        self.top_key_num = top_key_num
        self.compare_window = compare_window
        
    def get_top_key(self,result,abs=False):
        left_cor  = 0
        right_cor =-1
        if self.compare_window[0]  and self.compare_window[1] :
            left_cor,right_cor = self.compare_window[0],self.compare_window[1]
        print(f">> Compare range (max correlation) = ({left_cor},{right_cor})")
        max_cor = {}
        for key in self.guess_keys:
            max_cor[key] = np.max(np.abs(result[key][0][left_cor:right_cor])) if abs else np.max(result[key][0][left_cor:right_cor])
        sorted_items = sorted(max_cor.items(), key=lambda x: x[1], reverse=True)
        # è·å–å‰ n ä¸ªé”®
        top_keys = [item[0] for item in sorted_items[:self.top_key_num]]
        return np.array(top_keys)


    def draw_result(self, result,highlight_keys=None, zoom_range=None, save_path=None,show_max=False):
        """
        å¯è§†åŒ– CPA åˆ†æç»“æœ
        å‚æ•°:
        highlight_keys: éœ€è¦çªå‡ºæ˜¾ç¤ºçš„å¯†é’¥åˆ—è¡¨
        zoom_range: è¦æ”¾å¤§çš„æ ·æœ¬èŒƒå›´ (start, end)
        save_path: å›¾åƒä¿å­˜è·¯å¾„
        """
        print("ğŸ“Š å‡†å¤‡å¯è§†åŒ–ç»“æœ...")
        all_corrs = np.array([result[key].flatten() for key in self.guess_keys])
        print('Data read finish')
        # åˆ›å»ºå›¾å½¢å’Œåæ ‡è½´
        fig = plt.figure(figsize=(14, 8))
        
        index_max = np.argmax(np.abs(all_corrs))
        max_key = index_max//self.sample_number
        max_index = index_max - (index_max//self.sample_number)*self.sample_number
        print(f'max r {np.max(np.abs(all_corrs))},arg {index_max},-> key:{max_key}, index:{max_index}')
        key_max = index_max//self.sample_number ## Need to modify use self.guess_keys
        if zoom_range:
            # å¦‚æœæœ‰ç¼©æ”¾èŒƒå›´ï¼Œåˆ›å»ºä¸¤ä¸ªå­å›¾ï¼šå…¨å±€è§†å›¾å’Œæ”¾å¤§è§†å›¾
            ax1 = plt.subplot(2, 1, 1)  # å…¨å±€è§†å›¾
            ax2 = plt.subplot(2, 1, 2)  # æ”¾å¤§è§†å›¾
            axes = (ax1, ax2)
        else:
            # å¦åˆ™åªåˆ›å»ºå•ä¸ªè§†å›¾
            ax = plt.subplot(1, 1, 1)
            axes = (ax,)

        # ç»˜åˆ¶æ‰€æœ‰å¯†é’¥çš„ç›¸å…³ç³»æ•°æ›²çº¿ (é«˜æ€§èƒ½æ–¹å¼)
        for ax in axes:
            # ä½¿ç”¨é€æ˜æµ…è‰²ç»˜åˆ¶æ‰€æœ‰æ›²çº¿
            x = np.arange(self.sample_number)
            segments = np.array([np.column_stack([x, y]) for y in all_corrs])
            norm = plt.Normalize(0, len(all_corrs))
            lc = LineCollection(segments, cmap='Greys', norm=norm, alpha=0.1, linewidth=0.3)
            ax.add_collection(lc)
            # è®¾ç½®åæ ‡è½´èŒƒå›´
            ax.set_xlim(0, self.sample_number)
            ax.set_ylim(-1, 1)  # ç›¸å…³ç³»æ•°èŒƒå›´
            #ax.set_ylim(-0.5, 0.35)  # ç›¸å…³ç³»æ•°èŒƒå›´
            # æ·»åŠ ç½‘æ ¼
            ax.grid(True, linestyle='--', alpha=0.6)
            # æ·»åŠ æ ‡ç­¾
            ax.set_xlabel('samples index')
            ax.set_ylabel('correlation')
        # åˆ›å»ºé«˜å¯¹æ¯”åº¦é¢œè‰²åˆ—è¡¨ï¼ˆé¿å…è“è‰²ï¼‰
        
        # çªå‡ºæ˜¾ç¤ºç‰¹å®šå¯†é’¥
        if highlight_keys:
            print(f"highlight key: {highlight_keys}")
            #colors = plt.cm.tab10(np.linspace(0, 1, len(highlight_keys)))
            
            for ax in axes:
                for i, key in enumerate(highlight_keys):
                    if key in self.guess_keys:
                        corr = result[key].flatten()
                        label = f'key {key}'
                        ax.plot(corr, color=high_contrast_colors[i%10], linewidth=2, alpha=0.9, label=label)
                corr_max = result[key_max].flatten()
                if show_max:
                    label_max = f'key max {key_max}' 
                    ax.plot(corr_max, color=high_contrast_colors[9], linewidth=2, alpha=0.9, label=label_max)
                # æ·»åŠ å›¾ä¾‹
                ax.legend(loc='upper right')

        # è®¾ç½®ç¼©æ”¾è§†å›¾èŒƒå›´
        if zoom_range:
            ax2.set_title(f'zoom in ({zoom_range[0]}-{zoom_range[1]} samples)')
            ax2.set_xlim(zoom_range)

            # åœ¨å…¨å±€è§†å›¾ä¸­æ ‡è®°ç¼©æ”¾åŒºåŸŸ
            ax1.axvspan(zoom_range[0], zoom_range[1], color='yellow', alpha=0.2)
            ax1.text(zoom_range[0], 0.9, 'zoom in region', fontsize=10,
                    bbox=dict(facecolor='yellow', alpha=0.5))

        # æ·»åŠ æ ‡é¢˜
        title = f'CPA result ({self.key_number} keys, {self.sample_number} samples)'
        if highlight_keys:
            title += f'\nhighlight key(s): {", ".join(map(str, highlight_keys))}'
        plt.suptitle(title, fontsize=14)

        plt.tight_layout()

        # ä¿å­˜æˆ–æ˜¾ç¤º
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… ç»“æœå·²ä¿å­˜è‡³: {save_path}")
        else:
            plt.show()

    def draw_fig1(self,result,keys_to_plot_np,time_tag,special_b=2773,key_min=0,key_max=3328,roi_start=None,roi_en=None):
        """
        ç»˜åˆ¶æ‰€æœ‰çŒœæµ‹å¯†é’¥çš„ç›¸å…³ç³»æ•°éšæ—¶é—´å˜åŒ–çš„å›¾ï¼Œå¹¶é«˜äº®æ˜¾ç¤ºç‰¹å®šå¯†é’¥ã€‚
        """
        # ----- figure 1: Correlation vs Time ----- #
        print(f"INFO: Generating figure 1...")
     

        plt.figure(figsize=(15, 8))

        highlight_list = list(keys_to_plot_np)
        # Choose whether add special_b
        # if key_min <= special_b <= key_max and special_b not in highlight_list:
        #     highlight_list.append(special_b)
        if special_b in self.guess_keys and special_b not in highlight_list:
            highlight_list.append(special_b)

        # --- Draw Background --- #
        print("INFO: Plotting background correlation curves...")
        # for b_guess in range(key_min, key_max + 1):
        for b_guess in self.guess_keys:
            if b_guess in highlight_list:
                continue    # skip

            if(b_guess - key_min) % 200 == 0:
                print(f">>> Plotting background curve: {b_guess}/{key_max}")

            corrs, valid_indices = result[b_guess][0],[i for i in range(self.sample_number)]
            if corrs is not None and len(valid_indices) > 0:
                # Use grey slim transparent line to draw background
                # print(f">>> {len(valid_indices)}")
                plt.plot(valid_indices, corrs, color='lightgray', linewidth=0.5, alpha=0.7, zorder=1)


        print(f"INFO: Plotting highlighted correlation curves...")

        colors = plt.cm.viridis(np.linspace(0, 1, len(highlight_list))) # ä¸º5æ¡æ›²çº¿é€‰æ‹©ä¸åŒé¢œè‰²
        for i, b_guess in enumerate(highlight_list):
            corrs, valid_indices = result[b_guess][0],[i for i in range(self.sample_number)]
            if corrs is not None:
                # ç‰¹æ®Šå¤„ç† b_guess = special_b çš„æ ·å¼
                if b_guess == special_b:
                    style_kwargs = {'color': 'red', 'linestyle': '--', 'zorder': 100, 'linewidth': 1, 'label': f'special_b = {b_guess}'}
                else:
                    style_kwargs = {'color': colors[i], 'zorder': 50+i, 'linewidth': 0.8, 'label': f'b = {b_guess}'}

                plt.plot(valid_indices, corrs, **style_kwargs)
                # --- æ ‡æ³¨å³°å€¼ --- #
                # peak_idx_in_corrs = np.argmax(np.abs(corrs))
                # æ‰¾å‡ºæœ€å¤§çš„ç›¸å…³ç³»æ•°å€¼ï¼ˆä¸å–ç»å¯¹å€¼ï¼‰
                indices_for_peak = valid_indices
                corrs_for_peak = corrs

                if roi_start is not None and roi_en is not None: 
                    mask = (valid_indices >= roi_start) & (valid_indices <= roi_en)
                    indices_for_peak = valid_indices[mask]
                    corrs_for_peak = corrs[mask]

                if corrs_for_peak.size > 0:

                    peak_idx_in_corrs = np.argmax(corrs_for_peak)
                    x_peak = indices_for_peak[peak_idx_in_corrs]
                    y_peak = corrs_for_peak[peak_idx_in_corrs]
                    plt.annotate(f'({x_peak}, {y_peak:.3f})', 
                                 xy=(x_peak, y_peak), 
                                 xytext=(x_peak, y_peak + 0.03),
                                 ha='center',
                                 arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=4),
                                 zorder=101)

        plt.title('Pearson Coefficient vs. Time')
        plt.xlabel('Time')
        plt.ylabel('Correlation Coefficient (rho)')
        plt.legend()
        plt.grid(True)
        plt.axhline(0, color='black', linewidth=0.5)

        # è®¾ç½®çºµè½´èŒƒå›´ (å¯æ ¹æ®éœ€è¦è°ƒæ•´)
        plt.ylim(-0.2, 0.2)  # ä¾‹å¦‚ï¼šè®¾ç½®çºµè½´èŒƒå›´ä¸º -0.5 åˆ° 0.5
        time_path = os.path.join(self.save_path,time_tag+'/')
        os.makedirs(time_path,exist_ok=True)
        fig1_path = os.path.join(self.save_path,time_tag+'/', 'fig1_corrs_over_time.png')
        plt.savefig(fig1_path, dpi=300)
        print(f"[+] å›¾1å·²ä¿å­˜è‡³: {fig1_path}")
        plt.close()
    
    def draw_fig2(self,result,keys_to_plot_np,time_tag,special_b=2773,key_min=0,key_max=3328,roi_start=None,roi_en=None):
        """
        ç»˜åˆ¶æ¯ä¸ªçŒœæµ‹å¯†é’¥çš„æœ€å¤§ç›¸å…³ç³»æ•°å›¾ã€‚
        """
            # ----- figure 2: Correlation vs b_guess ----- #
        print(f"INFO: Generating figure 2...")

        plt.figure(figsize=(15, 8))
        # å®šä¹‰ç»˜å›¾çš„xè½´èŒƒå›´å’Œyè½´æ•°æ®
        max_corrs = {key:np.max(result[key][0]) for key in self.guess_keys} 
        #b_range_to_plot = np.arange(key_min, key_max + 1)
        b_range_to_plot = np.array(self.guess_keys)
        # corrs_to_plot = max_corrs[key_min : key_max + 1]
        corrs_to_plot = np.array([max_corrs[key] for key in self.guess_keys])
        plt.plot(b_range_to_plot, corrs_to_plot, alpha=0.6, label='All b_guess correlation')
        # plt.plot(range(N_guess), max_corrs, alpha=0.6, label='All b_guess correlation')

        # æ ‡æ³¨Top 5çš„ç‚¹
        for b_guess in keys_to_plot_np:
            y_val = max_corrs[b_guess]
            plt.plot(b_guess, y_val, 'bo', markersize=8, zorder=10) # 'ro' = red circle
            plt.annotate(f'({b_guess}, {y_val:.4f})',
                         xy=(b_guess, y_val),
                         xytext=(b_guess, y_val + 0.01),
                         ha='center',
                         fontsize=9,
                         zorder=11)

        # ç‰¹æ®Šæ ‡æ³¨ b_guess = special_b
        if special_b not in keys_to_plot_np and special_b in self.guess_keys:
            y_val = max_corrs[special_b]
            plt.plot(special_b, y_val, 'ro', markersize=8, zorder=10) # 'bo' = blue circle
            plt.annotate(f'({special_b}, {y_val:.4f})',
                         xy=(special_b, y_val),
                         xytext=(special_b, y_val + 0.01),
                         ha='center',
                         color='blue',
                         fontsize=9,
                         zorder=11)


        plt.title('Every guess of \'b\'\'s maximum correlation coefficient')
        plt.xlabel('\'b\'\'s guess value')
        plt.ylabel('Maximum absolute correlation coefficient')
        plt.legend([plt.Line2D([0], [0], color='w')], [f'Found key: b={keys_to_plot_np[0]}']) # ç®€åŒ–å›¾ä¾‹
        plt.grid(True)
        time_path = os.path.join(self.save_path,time_tag+'/')
        os.makedirs(time_path,exist_ok=True)
        fig2_path = os.path.join(self.save_path,time_tag+'/', 'fig2_cpa_result.png')
        plt.savefig(fig2_path, dpi=300)
        print(f"[+] å›¾2å·²ä¿å­˜è‡³: {fig2_path}")
        plt.close()

if __name__ == "__main__":
    pass